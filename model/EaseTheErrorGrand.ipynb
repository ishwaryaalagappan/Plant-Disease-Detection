{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms,models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root='C:\\\\Ishwarya\\\\Python\\\\mydata1', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "split = int(np.floor(0.85 * len(dataset)))  # train_size\n",
    "validation = int(np.floor(0.70 * split))  # validation\n",
    "np.random.shuffle(indices)\n",
    "train_indices, validation_indices, test_indices = (\n",
    "    indices[:validation],\n",
    "    indices[validation:split],\n",
    "    indices[split:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=train_sampler\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=test_sampler\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=validation_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to C:\\Users\\alagu/.cache\\torch\\hub\\checkpoints\\vgg16_bn-6c64b313.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfa49a68b604795a250afff33c824d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=553507836), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vgg=models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "final_in_features = vgg.classifier[6].in_features\n",
    "vgg.classifier[6] = nn.Linear(final_in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4096])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for param in vgg.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, train_loader, validation_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    validation_losses = np.zeros(epochs)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            train_loss.append(loss.item())  # torch to numpy world\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        validation_loss = []\n",
    "\n",
    "        for inputs, targets in validation_loader:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            validation_loss.append(loss.item())  # torch to numpy world\n",
    "            \n",
    "        validation_loss = np.mean(validation_loss)\n",
    "\n",
    "        train_losses[e] = train_loss\n",
    "        validation_losses[e] = validation_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "        print(f\"Epoch : {e+1}/{epochs} Train_loss:{train_loss:.3f} Test_loss:{validation_loss:.3f} Duration:{dt}\")\n",
    "\n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader( dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/1 Train_loss:0.299 Test_loss:0.186 Duration:0:18:27.286040\n"
     ]
    }
   ],
   "source": [
    "train_losses, validation_losses = batch_gd(vgg, criterion, train_loader, validation_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg.state_dict() , 'plant_disease_model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_size = 2\n",
    "#vgg = CNN(targets_size)\n",
    "vgg.load_state_dict(torch.load(\"plant_disease_model_1.pt\"))\n",
    "vgg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses , label = 'train_loss')\n",
    "plt.plot(validation_losses , label = 'validation_loss')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy(train_loader)\n",
    "test_acc = accuracy(test_loader)\n",
    "validation_acc = accuracy(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.972107212900414\n",
      "Test Accuracy : 0.957685664939551\n",
      "Validation Accuracy : 0.9659379766141332\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy : {train_acc}\\nTest Accuracy : {test_acc}\\nValidation Accuracy : {validation_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=[['Apple_scab'],['Apple_healthy'],['BellPepper_Bacterial_spot'],['BellPepper_healthy'],['Tomato_Early_blight'],['Tomato_healthy']]\n",
    "df=pd.DataFrame(data,columns=['disease_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_prediction(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    input_data = TF.to_tensor(image)\n",
    "    input_data = input_data.view((-1, 3, 224, 224))\n",
    "    output = vgg(input_data)\n",
    "    output = output.detach().numpy()\n",
    "    index = np.argmax(output)\n",
    "    print(\"Original : \", image_path[66:-4])\n",
    "    pred_csv = df[\"disease_name\"][index]\n",
    "    print(pred_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :  pepper_bell_healthy\n",
      "BellPepper_healthy\n"
     ]
    }
   ],
   "source": [
    "single_prediction(\"C:\\\\Users\\\\alagu\\\\Downloads\\\\Plant-Disease-Detection-main\\\\test_images\\\\pepper_bell_healthy.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
